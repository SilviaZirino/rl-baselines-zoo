atari:
  policy: 'CnnPolicy'
  n_timesteps: !!float 1e7
  buffer_size: 10000
  learning_rate: !!float 1e-4
  learning_starts: 10000
  target_network_update_freq: 1000
  train_freq: 4
  exploration_final_eps: 0.01
  exploration_fraction: 0.1
  prioritized_replay_alpha: 0.6
  prioritized_replay: True

CartPole-v1:
  n_timesteps: !!float 1e5
  policy: 'CustomDQNPolicy'
  learning_rate: !!float 1e-3
  buffer_size: 50000
  exploration_fraction: 0.1
  exploration_final_eps: 0.02
  prioritized_replay: True

MountainCar-v0:
  n_timesteps: 100000
  policy: 'CustomDQNPolicy'
  learning_rate: !!float 1e-3
  buffer_size: 50000
  exploration_fraction: 0.1
  exploration_final_eps: 0.1
  param_noise: True

LunarLander-v2:
  n_timesteps: !!float 2e5
  policy: 'CustomDQNPolicy'
  learning_rate: !!float 1e-3
  buffer_size: 100000
  exploration_fraction: 0.1
  exploration_final_eps: 0.05
  prioritized_replay: True

Acrobot-v1:
  n_timesteps: !!float 1e5
  policy: 'CustomDQNPolicy'
  learning_rate: !!float 1e-3
  buffer_size: 50000
  exploration_fraction: 0.1
  exploration_final_eps: 0.02
  prioritized_replay: True

Toy2D-v0:
  env_wrapper: stable_baselines.common.atari_wrappers.WarpFrame
  policy: 'CnnPolicy'
  n_timesteps: !!float 4e6
  buffer_size: 10000
  learning_rate: !!float 1e-4
  learning_starts: 10000
  target_network_update_freq: 2000
  train_freq: 4
  exploration_final_eps: 0.01
  exploration_fraction: 0.1
  prioritized_replay_alpha: 0.6
  prioritized_replay: True


CameraReach-v0:
  env_wrapper: RGBobs_ddpg.RGBobs #64x64 or 84x84?
  policy: 'CnnPolicy'
  n_timesteps: !!float 5e6
  buffer_size: 10000
  learning_rate: !!float 1e-4 #0.0025?
  learning_starts: 10000
  target_network_update_freq: 4000 #100?
  train_freq: 4
  exploration_final_eps: 0.01
  exploration_fraction: 0.2 #prima era 0.1
  prioritized_replay_alpha: 0.6
  prioritized_replay: True
  double_q: True
# gamma: 0.2 ??

 
CameraReach-v1:
  env_wrapper: stable_baselines.common.atari_wrappers.WarpFrame
  policy: 'CnnPolicy'
  n_timesteps: !!float 5e6
  buffer_size: 10000
  learning_rate: !!float 1e-4
  learning_starts: 10000
  target_network_update_freq: 3000
  train_freq: 4
  exploration_final_eps: 0.01
  exploration_fraction: 0.1
  prioritized_replay_alpha: 0.6
  prioritized_replay: True

